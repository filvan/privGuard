from __future__ import print_function
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns #visualization
import matplotlib.pyplot as plt #visualization
%matplotlib inline
from sklearn.ensemble import RandomForestClassifier
import itertools
import warnings
warnings.filterwarnings("ignore")
import os
import io
import plotly.offline as py #visualization
py.init_notebook_mode(connected=True) #visualization
import plotly.graph_objs as go #visualization
import plotly.tools as tls #visualization

# Import different models
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
# Scoring function
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.model_selection import cross_val_score

from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint
from sklearn.preprocessing import FunctionTransformer, StandardScaler
from sklearn.ensemble import VotingClassifier


def run(data_folder, **kwargs):
    # Read the training dataset
    training_data = pd.read_csv('../input/Churn_Modelling.csv')
    training_data.head()
    # Convert all columns heading in lowercase
    clean_column_name = []
    columns = training_data.columns
    for i in range(len(columns)):
        clean_column_name.append(columns[i].lower())
    training_data.columns = clean_column_name
    # Drop the irrelevant columns  as shown above
    training_data = training_data.drop(["rownumber", "customerid", "surname"], axis=1)
    # Separating churn and non churn customers
    churn = training_data[training_data["exited"] == 1]
    not_churn = training_data[training_data["exited"] == 0]
    target_col = ["exited"]
    cat_cols = training_data.nunique()[training_data.nunique() < 6].keys().tolist()
    cat_cols = [x for x in cat_cols if x not in target_col]
    num_cols = [x for x in training_data.columns if x not in cat_cols + target_col]
    # Print the first 5 lines of the dataset
    training_data.head()
    # View the dimension of the dataset
    training_data.shape
    # Checking for unique value in the data attributes
    training_data.nunique()
    # Describe the all statistical properties of the training dataset
    training_data[training_data.columns[:10]].describe()
    # Median
    training_data[training_data.columns[:10]].median()
    # Mean
    training_data[training_data.columns[:10]].mean()
    # Percentage per category for the target column.
    percentage_labels = training_data['exited'].value_counts(normalize=True) * 100
    percentage_labels
    # Graphical representation of the target label percentage.
    total_len = len(training_data['exited'])
    sns.set()
    sns.countplot(training_data.exited).set_title('Data Distribution')
    ax = plt.gca()
    for p in ax.patches:
        height = p.get_height()
        ax.text(p.get_x() + p.get_width() / 2.,
                height + 2,
                '{:.2f}%'.format(100 * (height / total_len)),
                fontsize=14, ha='center', va='bottom')
    sns.set(font_scale=1.5)
    ax.set_xlabel("Labels for exited column")
    ax.set_ylabel("Numbers of records")
    plt.show()
    plot_pie(cat_cols[0])
    plot_pie(cat_cols[1])
    plot_pie(cat_cols[2])
    plot_pie(cat_cols[3])
    plot_pie(cat_cols[4])
    histogram(num_cols[0])
    histogram(num_cols[1])
    histogram(num_cols[2])
    histogram(num_cols[3])
    histogram(num_cols[4])
    training_data.isnull().sum()
    training_data[training_data.columns].corr()
    sns.set()
    sns.set(font_scale=1.25)
    sns.heatmap(training_data[training_data.columns[:10]].corr(), annot=True, fmt=".1f")
    plt.show()
    trace = []

    def gen_boxplot(df):
        for feature in df:
            trace.append(
                go.Box(
                    name=feature,
                    y=df[feature]
                )
            )

    new_df = training_data[num_cols[:1]]
    gen_boxplot(new_df)
    data = trace
    py.iplot(data)
    trace = []

    def gen_boxplot(df):
        for feature in df:
            trace.append(
                go.Box(
                    name=feature,
                    y=df[feature]
                )
            )

    new_df = training_data[num_cols[1:3]]
    gen_boxplot(new_df)
    data = trace
    py.iplot(data)
    ageNew = []
    for val in training_data.age:
        if val <= 85:
            ageNew.append(val)
        else:
            ageNew.append(training_data.age.median())

    training_data.age = ageNew
    trace = []

    def gen_boxplot(df):
        for feature in df:
            trace.append(
                go.Box(
                    name=feature,
                    y=df[feature]
                )
            )

    new_df = training_data[num_cols[3:]]
    gen_boxplot(new_df)
    data = trace
    py.iplot(data)
    list_cat = ['geography', 'gender']
    training_data = pd.get_dummies(training_data, columns=list_cat, prefix=list_cat)
    training_data.head()

    X = training_data.drop('exited', axis=1)
    y = training_data.exited
    features_label = X.columns
    forest = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)
    forest.fit(X, y)
    importances = forest.feature_importances_
    indices = np.argsort(importances)[::-1]
    for i in range(X.shape[1]):
        print("%2d) %-*s %f" % (i + 1, 30, features_label[i], importances[indices[i]]))

    plt.title('Feature Importances')
    plt.bar(range(X.shape[1]), importances[indices], color="green", align="center")
    plt.xticks(range(X.shape[1]), features_label, rotation=90)
    plt.show()

    #Train and build baseline model
    X = training_data.drop('exited', axis=1)
    y = training_data.exited
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
    # Initialization of the KNN
    knMod = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2,
                                 metric='minkowski', metric_params=None)
    # Fitting the model with training data
    knMod.fit(X_train, y_train)

    lrMod = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True,
                               intercept_scaling=1, class_weight=None,
                               random_state=None, solver='liblinear', max_iter=100,
                               multi_class='ovr', verbose=2)
    # Fitting the model with training data
    lrMod.fit(X_train, y_train)
    adaMod = AdaBoostClassifier(base_estimator=None, n_estimators=200, learning_rate=1.0)
    # Fitting the model with training data
    adaMod.fit(X_train, y_train)
    gbMod = GradientBoostingClassifier(loss='deviance', n_estimators=200)
    # Fitting the model with training data
    gbMod.fit(X_train, y_train)
    # Initialization of the Random Forest model
    rfMod = RandomForestClassifier(n_estimators=10, criterion='gini')
    # Fitting the model with training data
    rfMod.fit(X_train, y_train)
    # Compute the model accuracy on the given test data and labels
    knn_acc = knMod.score(X_test, y_test)
    # Return probability estimates for the test data
    test_labels = knMod.predict_proba(np.array(X_test.values))[:, 1]
    # Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores
    knn_roc_auc = roc_auc_score(y_test, test_labels, average='macro', sample_weight=None)
    lr_acc = lrMod.score(X_test, y_test)
    # Return probability estimates for the test data
    test_labels = lrMod.predict_proba(np.array(X_test.values))[:, 1]
    # Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores
    lr_roc_auc = roc_auc_score(y_test, test_labels, average='macro', sample_weight=None)
    ada_acc = adaMod.score(X_test, y_test)
    # Return probability estimates for the test data
    test_labels = adaMod.predict_proba(np.array(X_test.values))[:, 1]
    # Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores
    ada_roc_auc = roc_auc_score(y_test, test_labels, average='macro')
    gb_acc = gbMod.score(X_test, y_test)
    # Return probability estimates for the test data
    test_labels = gbMod.predict_proba(np.array(X_test.values))[:, 1]
    # Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores
    gb_roc_auc = roc_auc_score(y_test, test_labels, average='macro')
    rf_acc = rfMod.score(X_test, y_test)
    # Return probability estimates for the test data
    test_labels = rfMod.predict_proba(np.array(X_test.values))[:, 1]
    # Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores
    rf_roc_auc = roc_auc_score(y_test, test_labels, average='macro')
    models = ['KNN', 'Logistic Regression', 'AdaBoost', 'GradientBoosting', 'Random Forest']
    accuracy = [knn_acc, lr_acc, ada_acc, gb_acc, rf_acc]
    roc_auc = [knn_roc_auc, lr_roc_auc, ada_roc_auc, gb_roc_auc, rf_roc_auc]

    d = {'accuracy': accuracy, 'roc_auc': roc_auc}
    df_metrics = pd.DataFrame(d, index=models)
    df_metrics
    fpr_knn, tpr_knn, _ = roc_curve(y_test, knMod.predict_proba(np.array(X_test.values))[:, 1])
    fpr_lr, tpr_lr, _ = roc_curve(y_test, lrMod.predict_proba(np.array(X_test.values))[:, 1])
    fpr_ada, tpr_ada, _ = roc_curve(y_test, adaMod.predict_proba(np.array(X_test.values))[:, 1])
    fpr_gb, tpr_gb, _ = roc_curve(y_test, gbMod.predict_proba(np.array(X_test.values))[:, 1])
    fpr_rf, tpr_rf, _ = roc_curve(y_test, rfMod.predict_proba(np.array(X_test.values))[:, 1])
    plt.figure(figsize=(12, 6), linewidth=1)
    plt.plot(fpr_knn, tpr_knn, label='KNN Score: ' + str(round(knn_roc_auc, 5)))
    plt.plot(fpr_lr, tpr_lr, label='LR score: ' + str(round(lr_roc_auc, 5)))
    plt.plot(fpr_ada, tpr_ada, label='AdaBoost Score: ' + str(round(ada_roc_auc, 5)))
    plt.plot(fpr_gb, tpr_gb, label='GB Score: ' + str(round(gb_roc_auc, 5)))
    plt.plot(fpr_rf, tpr_rf, label='RF score: ' + str(round(rf_roc_auc, 5)))
    plt.plot([0, 1], [0, 1], 'k--', label='Random guessing: 0.5')
    plt.xlabel('False positive rate')
    plt.ylabel('True positive rate')
    plt.title('ROC Curve ')
    plt.legend(loc='best')
    plt.show()

    mod = [knMod, lrMod, adaMod, gbMod, rfMod]
    cvD = cvDictGen(mod, scr='roc_auc')
    cvD
    adaHyperParams = {'n_estimators': [10, 50, 100, 200, 420]}
    gridSearchAda = RandomizedSearchCV(estimator=adaMod, param_distributions=adaHyperParams, n_iter=5,
                                       scoring='roc_auc')
    gridSearchAda.fit(X_train, y_train)
    gridSearchAda.best_params_, gridSearchAda.best_score_
    gbHyperParams = {'loss': ['deviance', 'exponential'],
                     'n_estimators': randint(10, 500),
                     'max_depth': randint(1, 10)}
    gridSearchGB = RandomizedSearchCV(estimator=gbMod, param_distributions=gbHyperParams, n_iter=10,
                                      scoring='roc_auc')
    # Fitting the model
    gridSearchGB.fit(X_train, y_train)
    gridSearchGB.best_params_, gridSearchGB.best_score_
    bestGbModFitted = gridSearchGB.best_estimator_.fit(X_train, y_train)
    bestAdaModFitted = gridSearchAda.best_estimator_.fit(X_train, y_train)
    functions = [bestGbModFitted, bestAdaModFitted]
    cvDictbestpara = cvDictGen(functions, scr='roc_auc')
    cvDictbestpara
    test_labels = bestGbModFitted.predict_proba(np.array(X_test.values))[:, 1]
    roc_auc_score(y_test, test_labels, average='macro', sample_weight=None)
    test_labels = bestAdaModFitted.predict_proba(np.array(X_test.values))[:, 1]
    roc_auc_score(y_test, test_labels, average='macro', sample_weight=None)
    transformer = FunctionTransformer(np.log1p)
    scaler = StandardScaler()
    X_train_1 = np.array(X_train)
    #X_train_transform = transformer.transform(X_train_1)
    X_train_transform = scaler.fit_transform(X_train_1)
    bestGbModFitted_transformed = gridSearchGB.best_estimator_.fit(X_train_transform, y_train)
    bestAdaModFitted_transformed = gridSearchAda.best_estimator_.fit(X_train_transform, y_train)
    cvDictbestpara_transform = cvDictGen(functions=[bestGbModFitted_transformed, bestAdaModFitted_transformed],
                                         scr='roc_auc')
    cvDictbestpara_transform
    # For the test set
    X_test_1 = np.array(X_test)
    # X_test_transform = transformer.transform(X_test_1)
    X_test_transform = scaler.fit_transform(X_test_1)
    test_labels = bestGbModFitted_transformed.predict_proba(np.array(X_test_transform))[:, 1]
    roc_auc_score(y_test, test_labels, average='macro', sample_weight=None)
    votingMod = VotingClassifier(estimators=[('gb', bestGbModFitted_transformed),
                                             ('ada', bestAdaModFitted_transformed)],
                                             voting = 'soft', weights = [2,1])
    # Fitting the model
    votingMod = votingMod.fit(X_train_transform, y_train)
    test_labels=votingMod.predict_proba(np.array(X_test_transform))[:,1]
    votingMod.score(X_test_transform, y_test)
    roc_auc_score(y_test, test_labels, average='macro', sample_weight=None)
    votingMod_old = VotingClassifier(estimators=[('gb', bestGbModFitted), ('ada', bestAdaModFitted)],
                                     voting='soft', weights=[2, 1])
    # Fitting the model
    votingMod_old = votingMod.fit(X_train, y_train)
    test_labels = votingMod_old.predict_proba(np.array(X_test.values))[:, 1]
    votingMod.score(X_test, y_test)
    roc_auc_score(y_test, test_labels, average='macro', sample_weight=None)

def cvDictGen(functions, scr, X_train=X, y_train=y, cv=5):
    cvDict = {}
    for func in functions:
        cvScore = cross_val_score(func, X_train, y_train, cv=cv, scoring=scr)
        cvDict[str(func).split('(')[0]] = [cvScore.mean(), cvScore.std()]

    return cvDict
def histogram(column):
    trace1 = go.Histogram(x=churn[column],
                          histnorm="percent",
                          name="Churn Customers",
                          marker=dict(line=dict(width=.5,
                                                color="black"
                                                )
                                      ),
                          opacity=.9
                          )

    trace2 = go.Histogram(x=not_churn[column],
                          histnorm="percent",
                          name="Non churn customers",
                          marker=dict(line=dict(width=.5,
                                                color="black"
                                                )
                                      ),
                          opacity=.9
                          )

    data = [trace1, trace2]
    layout = go.Layout(dict(title=column + " distribution in customer attrition ",
                            plot_bgcolor="rgb(243,243,243)",
                            paper_bgcolor="rgb(243,243,243)",
                            xaxis=dict(gridcolor='rgb(255, 255, 255)',
                                       title=column,
                                       zerolinewidth=1,
                                       ticklen=5,
                                       gridwidth=2
                                       ),
                            yaxis=dict(gridcolor='rgb(255, 255, 255)',
                                       title="percent",
                                       zerolinewidth=1,
                                       ticklen=5,
                                       gridwidth=2
                                       ),
                            )
                       )
    fig = go.Figure(data=data, layout=layout)

    py.iplot(fig)

def plot_pie(column):
    trace1 = go.Pie(values=churn[column].value_counts().values.tolist(),
                    labels=churn[column].value_counts().keys().tolist(),
                    hoverinfo="label+percent+name",
                    domain=dict(x=[0, .48]),
                    name="Churn Customers",
                    marker=dict(line=dict(width=2,
                                          color="rgb(243,243,243)")
                                ),
                    hole=.6
                    )
    trace2 = go.Pie(values=not_churn[column].value_counts().values.tolist(),
                    labels=not_churn[column].value_counts().keys().tolist(),
                    hoverinfo="label+percent+name",
                    marker=dict(line=dict(width=2,
                                          color="rgb(243,243,243)")
                                ),
                    domain=dict(x=[.52, 1]),
                    hole=.6,
                    name="Non churn customers"
                    )

    layout = go.Layout(dict(title=column + " distribution in customer attrition ",
                            plot_bgcolor="rgb(243,243,243)",
                            paper_bgcolor="rgb(243,243,243)",
                            annotations=[dict(text="churn customers",
                                              font=dict(size=13),
                                              showarrow=False,
                                              x=.15, y=.5),
                                         dict(text="Non churn customers",
                                              font=dict(size=13),
                                              showarrow=False,
                                              x=.88, y=.5
                                              )
                                         ]
                            )
                       )
    data = [trace1, trace2]
    fig = go.Figure(data=data, layout=layout)
    py.iplot(fig)
